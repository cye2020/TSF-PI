{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/cye2020/TSF-SPI.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd TSF-SPI/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git pull","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# User-defined Data preprocessor\nfrom utils.data_loader import DataLoader\nfrom utils.spliter import WindowGenerator\n\n# User-defined Visualization and Print Results\nfrom utils.plot_util import plot\nfrom utils.evaluation import printResult\n\n# Model Callbacks\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n\n# Model Optimizer\nfrom tensorflow.keras.optimizers import Adam, RMSprop, SGD\n\n# Dataframe\nimport pandas as pd\nimport numpy as np\n\n# Model Structure\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Conv1D, MaxPool1D, Input, Bidirectional, LSTM\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, InputLayer\nfrom tensorflow.keras import backend as K\n\n# Seed\nfrom tensorflow.random import set_seed\nfrom numpy.random import randint","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_loader = DataLoader()\nTarget = 'Kospi'\n\nfeatures = [Target, 'USD/KRW', 'GDP', 'IAIP', 'LIR', 'M1', 'disease']\n\ntrain, test, date_lists = data_loader.load_csv(path='./data/kospi.csv', \n                                               features=np.concatenate((['Date'],features), axis=0), \n                                               split_date='2021-01-01')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('./data/kospi.csv')\ndata.isnull().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"boolarr = np.isnan(test)\nboolarr.sum()\nnp.count_nonzero(boolarr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seedNum = 3394\nset_seed(seedNum)\nnp.random.seed(seedNum)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_input = (30, 1, 1)\n\nwg_1 = WindowGenerator(train, input_width=CNN_input[0], label_width=CNN_input[1], shift=CNN_input[2])\ntwg_1 = WindowGenerator(test, input_width=CNN_input[0], label_width=CNN_input[1], shift=CNN_input[2])\n\ntrain_cnn_x, train_cnn_y = wg_1.split_window()\ntest_cnn_x, test_cnn_y = twg_1.split_window()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv1D(64, 2, input_shape=(30,7)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool1D(pool_size = 2))\n\nmodel.add(Flatten())\nmodel.add(Dense(100))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 모델의 학습률입니다.\nLr = 0.001\n\n# 옵티마이저 함수입니다.\nOptimizer = Adam(learning_rate=Lr)\n\n# 학습하는 최대 Epoch(iterations)입니다.\nEpochs = 100\n\n# Train 데이터 중 validation 데이터의 비율을 정합니다. \nValidation_split=0.2\n\n# Batch size입니다.\nBatch_size = 64\n\n# 손실함수입니다.\nLoss = 'mean_squared_error'\n\n#callbacks\nes = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\nrlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Optimizer, loss=Loss)\n\nhistory = model.fit(train_cnn_x,\n                    train_cnn_y,\n                    shuffle=True,\n                    epochs=Epochs,\n                    callbacks=[es, rlr],\n                    validation_split=Validation_split,\n                    verbose=1,\n                    batch_size=Batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cnn_predict = model.predict(train_cnn_x)\ntest_cnn_predict = model.predict(test_cnn_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRUE = pd.DataFrame(data_loader.original[:, 0:1], columns=[\"True\"]).set_index(pd.Series(date_lists[0]))\nprediction_train = wg_1.to_pandas(train_cnn_predict[1:][:,-1], date_lists[1], name=\"Train\")\nprediction_test = twg_1.to_pandas(test_cnn_predict[1:][:,-1], date_lists[2], name=\"Test\")\n\nplot(TRUE, prediction_train, prediction_test, show=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"printResult(date_lists[2], test_cnn_y, test_cnn_predict, Target, features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}